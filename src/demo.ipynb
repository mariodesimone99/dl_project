{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyuv2_dataset import NYUv2Dataset\n",
    "from cityscapes_dataset import CityscapesDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from cross_stitchnet import CrossStitchNet\n",
    "from densenet import DenseNet\n",
    "from depthnet import DepthNet\n",
    "from splitnet import SplitNet\n",
    "from stan import STAN\n",
    "from mtan import MTAN\n",
    "from segnet import SegNet\n",
    "from normalnet import NormalNet\n",
    "from trainer import Trainer\n",
    "from utils import count_params, visualize_results, build_stats_dict\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_string = 'cityscapes'\n",
    "tasks = ['segmentation', 'depth'] if dataset_string == 'cityscapes' else ['segmentation', 'depth', 'normal']\n",
    "BATCH_SIZE = 8 if dataset_string == 'cityscapes' else 2\n",
    "LR = 1e-4\n",
    "filter = [64, 128, 256, 512, 512] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_string == 'nyuv2':\n",
    "    print(\"NYUv2 Dataset\")\n",
    "    nyuv2_train = NYUv2Dataset(root=\"../dataset/nyuv2_preprocessed\", split='train')\n",
    "    classes = nyuv2_train.get_classes()\n",
    "\n",
    "    nyuv2_val = NYUv2Dataset(root=\"../dataset/nyuv2_preprocessed\", split='val')\n",
    "    train_dl = DataLoader(nyuv2_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dl = DataLoader(nyuv2_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    for image, out in train_dl:\n",
    "        print('Image: ' + str(list(image.shape)) + ',' + ' Label: ' + str(list(out['segmentation'].shape)) + ',' + ' Depth: ' + str(list(out['depth'].shape)) + ',' + ' Normals: ' + str(list(out['normal'].shape)))\n",
    "        print(f'Image: {image.max().item()}, {image.min().item()}') \n",
    "        print('Label: ' +  str(out['segmentation'].max().item()) + ',' + str(out['segmentation'].min().item()))\n",
    "        print('Depth: ' + str(out['depth'].max().item()) + ', ' + str(out['depth'].min().item()))\n",
    "        print('Normals: ' + str(out['normal'].max().item()) + ', ' + str(out['normal'].min().item()))\n",
    "        break\n",
    "else:\n",
    "    print(\"Cityscapes Dataset\")\n",
    "    cityscapes_train = CityscapesDataset(root=\"../dataset/cityscapes_preprocessed\")\n",
    "    cityscapes_val = CityscapesDataset(root=\"../dataset/cityscapes_preprocessed\", split='val')\n",
    "    train_dl = DataLoader(cityscapes_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dl = DataLoader(cityscapes_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    classes = cityscapes_train.get_classes()\n",
    "    for image, out in train_dl:\n",
    "        print('Image: ' + str(list(image.shape)) + ',' + ' Label: ' + str(list(out['segmentation'].shape)) + ',' + ' Depth: ' + str(list(out['depth'].shape)))\n",
    "        print(f'Image: {image.max().item()}, {image.min().item()}') \n",
    "        print('Label: ' +  str(out['segmentation'].max().item()) + ', ' + str(out['segmentation'].min().item()))\n",
    "        print('Depth: ' + str(out['depth'].max().item()) + ', ' + str(out['depth'].min().item()))\n",
    "        for t in out.keys():\n",
    "            plt.imshow(out[t][0].cpu().numpy())\n",
    "            plt.savefig(f'../{dataset_string}_{t}')\n",
    "        break\n",
    "print(f\"Number of classes: {classes}\")\n",
    "\n",
    "for image, out in val_dl:\n",
    "    plt.imshow(image[0].permute(1,2,0).cpu().numpy())\n",
    "    plt.savefig(f'../{dataset_string}_image')\n",
    "    for t in out.keys():\n",
    "        if t == 'normal':\n",
    "            plt.imshow(out[t][0].permute(1,2,0).cpu().numpy())\n",
    "        elif t == 'depth':\n",
    "            plt.imshow(out[t][0].cpu().numpy(), cmap='jet')\n",
    "        else:\n",
    "            plt.imshow(out[t][0].cpu().numpy())\n",
    "        plt.savefig(f'../{dataset_string}_{t}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definitions and Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = CrossStitchNet(filter=filter, classes=classes, mid_layers=1, tasks=tasks)\n",
    "dense = DenseNet(filter=filter, classes=classes, mid_layers=0, tasks=tasks)\n",
    "depth = DepthNet(filter=filter, mid_layers=6)\n",
    "mtan = MTAN(filter=filter, mid_layers=0 , classes=classes, tasks=tasks)\n",
    "norm = NormalNet(filter=filter, mid_layers=6)\n",
    "seg = SegNet(filter=filter, mid_layers=6, classes=classes)\n",
    "split = SplitNet(filter=filter, mid_layers=6, classes=classes, tasks=tasks)\n",
    "stan = STAN(filter=filter, mid_layers=4, classes=classes, task=tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtan_params = count_params(mtan)\n",
    "cross_params = count_params(cross)\n",
    "dense_params = count_params(dense)\n",
    "depth_params = count_params(depth)\n",
    "norm_params = count_params(norm)\n",
    "seg_params = count_params(seg)\n",
    "split_params = count_params(split)\n",
    "stan_params = count_params(stan)\n",
    "print(f\"MTAN: {mtan_params}\")\n",
    "print(f\"Cross: {cross_params}, {cross_params>=mtan_params}\")\n",
    "print(f\"Dense: {dense_params}, {dense_params>=mtan_params}\")\n",
    "print(f\"Depth: {depth_params}, {depth_params>=mtan_params}\")\n",
    "print(f\"Norm: {norm_params}, {norm_params>=mtan_params}\")\n",
    "print(f\"Seg: {seg_params}, {seg_params>=mtan_params}\")\n",
    "print(f\"Split: {split_params}, {split_params>=mtan_params}\")\n",
    "print(f\"STAN: {stan_params}, {stan_params>=mtan_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mtan.to(device)\n",
    "print(f\"{model.name} has {count_params(model)} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "trainer = Trainer(model, opt, dataset_string, device, dwa=False, save_path='../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(train_dl, val_dl, epochs=5, save=False, check=1, grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwa_model = False\n",
    "model = DenseNet(filter=filter, classes=classes, mid_layers=0, tasks=tasks)\n",
    "# model = MTAN(classes=classes, tasks=tasks)\n",
    "# model = CrossStitchNet(classes=classes, mid_layers=1, tasks=tasks)\n",
    "# model = SplitNet(filter=filter, mid_layers=6, classes=classes, tasks=tasks)\n",
    "# model = DepthNet(filter=filter, mid_layers=6)\n",
    "# model = SegNet(filter=filter, mid_layers=6, classes=classes)\n",
    "# model = NormalNet(filter=filter, mid_layers=6)\n",
    "# model = STAN(filter=filter, mid_layers=4, classes=classes, task='segmentation')\n",
    "# model = STAN(filter=filter, mid_layers=4, classes=classes, task='depth')\n",
    "# model = STAN(filter=filter, mid_layers=4, classes=classes, task='normal')\n",
    "path = f'../models/{dataset_string}/{model.name}'\n",
    "if len(model.tasks) > 1:\n",
    "    path += '_dwa' if dwa_model else '_equal'\n",
    "path += f'/{model.name}_100.pth'\n",
    "print(path)\n",
    "model.load_state_dict(torch.load(path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nresults = 10\n",
    "id_result = 0\n",
    "for i, (image, out) in enumerate(val_dl):\n",
    "    state = visualize_results(model, device, image, out, id_result, nresults, out=True, save=True, save_path='../', dataset_str=dataset_string)\n",
    "    id_result += BATCH_SIZE\n",
    "    if state:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = build_stats_dict(model, device)\n",
    "stats_str = []\n",
    "stats_val = []\n",
    "train_stats = Trainer(model, None, dataset_string, device, dwa=dwa_model, save_path='../tmp')\n",
    "loss = train_stats._val_epoch(val_dl, stats)\n",
    "\n",
    "save_path = '../'\n",
    "if len(model.tasks) == 1:\n",
    "    path = save_path + f\"results/{dataset_string}/{model.name}\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "else:\n",
    "    dwa_string = 'dwa' if dwa_model else 'equal'\n",
    "    path = save_path +  f\"results/{dataset_string}/{model.name}_{dwa_string}\"\n",
    "    for t in model.tasks:\n",
    "        if not os.path.exists(path + f'/{t}'):\n",
    "            os.makedirs(path + f'/{t}')\n",
    "\n",
    "for k in stats.keys():\n",
    "    for t in stats[k].keys():\n",
    "        stat_comp = stats[k][t].compute()\n",
    "        if t != 'ad':\n",
    "            stats_str.append(t)\n",
    "            stat_tmp = stat_comp.cpu().item()\n",
    "            stats_val.append(f'{stat_tmp:.4f}')\n",
    "            print(f\"{t}: {stat_tmp:.4f}\")\n",
    "        else:\n",
    "            for i in stat_comp.keys():\n",
    "                if i != 'tolls':\n",
    "                    stat_tmp = stat_comp[i].cpu().item()\n",
    "                    stats_str.append(t + f'_{i}')\n",
    "                    stats_val.append(f'{stat_tmp:.4f}')\n",
    "                    print(f\"{t}_{i}: {stat_tmp:.4f}\")\n",
    "                else:\n",
    "                    for j in range(len(stat_comp[i])):\n",
    "                        stats_str.append(i + f'_{stats[k][t].tolls[j]}')\n",
    "                        stat_tmp = stat_comp[i][j].cpu().item()\n",
    "                        stats_val.append(f'{stat_tmp:.4f}')\n",
    "                        print(f\"{i}_{stats[k][t].tolls[j]}': {stat_tmp:.4f}\")\n",
    "np.savetxt(path + f'/stats.txt', [p for p in zip(stats_str, stats_val)], delimiter=': ', fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
